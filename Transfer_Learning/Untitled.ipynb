{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f49363-35be-4698-87f2-655e83a30ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629db8ae-991d-4ed8-98d7-12ee5263a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning) # ignore warnings\n",
    "\n",
    "image_shape = (224, 224)\n",
    "\n",
    "module = hub.load(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5\")\n",
    "# load the mobilenet_v2 image classification model from Tensorflow Hub\n",
    "\n",
    "def mobilenet_v2(input):\n",
    "    return module(input)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = image_shape + (3,)),\n",
    "    tf.keras.layers.Lambda(mobilenet_v2)\n",
    "])\n",
    "# classify without any changes, this will lead to errors because we need to modify the output layer as per our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b02077-7508-4b3e-a856-89ebaa049df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = Image.open(\"goldfish.jpg\").resize(image_shape)\n",
    "gold_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda920f-e45c-4c5a-bf13-b49e91654fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish) / 255 \n",
    "gold_fish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2e044-a610-447d-a446-7735dc2dba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gold_fish[np.newaxis, ...]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd5ce5-aad2-41ef-8139-47f7f5daa214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(img)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587393aa-cf50-4640-8ccf-21607ffe4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe36b3d-92b7-4d77-8d9e-0ae7fd683f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all image classes present in mobilenet_v2\n",
    "\n",
    "image_class = []\n",
    "\n",
    "with open ('ImageNetLabels.txt') as f:\n",
    "    for line in f:\n",
    "        image_class.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3351879-ceed-46be-8b4c-38510fa3b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_class[np.argmax(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65696ee-963d-4add-8a4c-a767948eef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path('..//Data_Augmentation//datasets//flower_photos')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f16249-219f-449a-92b3-b9491fcd2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17572e2c-3f15-4856-84da-22dd940f1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f293e80-6c01-46f1-a6e1-821a382813b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "roses[: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebbab82-7ca9-41ea-b312-51ca5f7cc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(roses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5cb51-8922-4218-aab0-a3e070804b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary containing image file paths for each flower class\n",
    "\n",
    "flower_image_path_dict = {\n",
    "    'daisy' : list(data_dir.glob('daisy/*')),\n",
    "    'dandelion' : list(data_dir.glob('dandelion/*')),\n",
    "    'roses' : list(data_dir.glob('roses/*')),\n",
    "    'sunflowers' : list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips' : list(data_dir.glob('tulips/*'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f62918-a7c6-402f-8af7-c586587194be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating label for each flower class\n",
    "\n",
    "flower_label_dict = {\n",
    "    'daisy' : 0,\n",
    "    'dandelion' : 1, \n",
    "    'roses' : 2,\n",
    "    'sunflowers' : 3, \n",
    "    'tulips' : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f8187-b28e-4c18-b95d-3caefc526fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating X and y for model \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for flower_name, flower_image_path in flower_image_path_dict.items():\n",
    "\n",
    "    for path in flower_image_path:\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        resized_img = cv2.resize(img, image_shape)\n",
    "\n",
    "        X.append(resized_img)\n",
    "        y.append(flower_label_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494b9ee-65ec-4de6-9422-ea323195f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3b1cc-15c1-46fe-9243-b1875c3d912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035758-7275-43d9-b731-665b78651af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)  # convert from float64 to float32 to reduce memory allocation on RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b6568-015c-47a1-aad5-22c03c374a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394042c0-569f-4adc-8162-10edf720588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8365c56-ad29-42d6-b2b6-ca867e4998b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcb96a-2d00-4159-94ab-bb31854db0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267610b-b672-4ba6-9faa-8641fe270973",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfe210-48f8-42b8-aa45-d57c8cd509b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X[2000]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f97d7-daa4-4a23-9093-1499009d27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(np.array([img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209eb95-e0f9-4903-b82a-14709cd985d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed627155-3d04-46b5-92db-37fea2451246",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_class[937]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc8b7e-380a-4ee8-b026-559640939c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = hub.load(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\")\n",
    "# convert the module from ./classification/4 to ./feature_vector/4 to modify output layer\n",
    "\n",
    "def mobilenet_v2(input):\n",
    "    return module(input)\n",
    "\n",
    "num_of_flowers = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = image_shape + (3, )),\n",
    "    tf.keras.layers.Lambda(mobilenet_v2),\n",
    "\n",
    "    tf.keras.layers.Dense(num_of_flowers) # modify the output layer by assigning number of nodes \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aceb23d-aba3-43aa-8702-8960842a219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer = \"adam\",\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d51972-c07c-4117-8d60-4000f161c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
