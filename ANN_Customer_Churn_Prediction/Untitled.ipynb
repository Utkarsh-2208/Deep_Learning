{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b00bff2-1468-492a-8204-3a6aff31558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93970a64-5304-426e-b459-a9a52b161474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a855872e-aa7d-4198-aa97-561d0f2200fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5090c25-813a-4e62-b698-a4367f800f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to number\n",
    "\n",
    "df1 = df.replace({'Male' : 0, 'Female' : 1})\n",
    "df2 = pd.get_dummies(df1, columns = ['Geography'], drop_first = True, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32dac57-8395-445c-90e3-4014b2e371dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "9995                0  \n",
       "9996                0  \n",
       "9997                0  \n",
       "9998                0  \n",
       "9999                0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f00fb98-fc6b-4ec5-a9bc-d42199f8230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop('Exited', axis = 1)\n",
    "y = df2['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9882759-6e86-4d0c-8ca2-2fad9c4ae725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sx = MinMaxScaler()\n",
    "\n",
    "X_scaled = sx.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfee528b-7531-4903-8544-06f1865ea39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2a1916-d846-42cd-ae45-6b6bc39ae51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bc9b3b-c668-40a2-80d2-1830a66ee3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.5645\n",
      "Epoch 2/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4945\n",
      "Epoch 3/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.4818\n",
      "Epoch 4/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.4689\n",
      "Epoch 5/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4600\n",
      "Epoch 6/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8071 - loss: 0.4521\n",
      "Epoch 7/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.4510\n",
      "Epoch 8/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4355\n",
      "Epoch 9/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.4348\n",
      "Epoch 10/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.4258\n",
      "Epoch 11/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.4125\n",
      "Epoch 12/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.4169\n",
      "Epoch 13/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.4149\n",
      "Epoch 14/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.4111\n",
      "Epoch 15/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.4172\n",
      "Epoch 16/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.4020\n",
      "Epoch 17/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4044\n",
      "Epoch 18/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8228 - loss: 0.3978\n",
      "Epoch 19/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8287 - loss: 0.3911\n",
      "Epoch 20/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.3901\n",
      "Epoch 21/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 0.3949\n",
      "Epoch 22/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3715\n",
      "Epoch 23/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8341 - loss: 0.3823\n",
      "Epoch 24/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.3766\n",
      "Epoch 25/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8299 - loss: 0.3911\n",
      "Epoch 26/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.3790\n",
      "Epoch 27/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.3729\n",
      "Epoch 28/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.3931\n",
      "Epoch 29/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.3765\n",
      "Epoch 30/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3731\n",
      "Epoch 31/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3664\n",
      "Epoch 32/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3689\n",
      "Epoch 33/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.3726\n",
      "Epoch 34/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.3656\n",
      "Epoch 35/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3733\n",
      "Epoch 36/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3732\n",
      "Epoch 37/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8447 - loss: 0.3629\n",
      "Epoch 38/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.3659\n",
      "Epoch 39/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.3596\n",
      "Epoch 40/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3686\n",
      "Epoch 41/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3636\n",
      "Epoch 42/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.3621\n",
      "Epoch 43/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3577\n",
      "Epoch 44/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.3689\n",
      "Epoch 45/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.3540\n",
      "Epoch 46/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.3511\n",
      "Epoch 47/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.3657\n",
      "Epoch 48/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3604\n",
      "Epoch 49/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3584\n",
      "Epoch 50/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3544\n",
      "Epoch 51/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3517\n",
      "Epoch 52/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3640\n",
      "Epoch 53/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.3585\n",
      "Epoch 54/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3615\n",
      "Epoch 55/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.3539\n",
      "Epoch 56/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3633\n",
      "Epoch 57/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3610\n",
      "Epoch 58/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3582\n",
      "Epoch 59/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.3555\n",
      "Epoch 60/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3533\n",
      "Epoch 61/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.3527\n",
      "Epoch 62/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3438\n",
      "Epoch 63/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3591\n",
      "Epoch 64/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3521\n",
      "Epoch 65/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3490\n",
      "Epoch 66/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3591\n",
      "Epoch 67/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3528\n",
      "Epoch 68/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3459\n",
      "Epoch 69/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3492\n",
      "Epoch 70/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3600\n",
      "Epoch 71/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3488\n",
      "Epoch 72/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3493\n",
      "Epoch 73/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3536\n",
      "Epoch 74/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3456\n",
      "Epoch 75/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3404\n",
      "Epoch 76/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8552 - loss: 0.3472\n",
      "Epoch 77/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3479\n",
      "Epoch 78/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3343\n",
      "Epoch 79/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3463\n",
      "Epoch 80/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 0.3472\n",
      "Epoch 81/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3594\n",
      "Epoch 82/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8572 - loss: 0.3430\n",
      "Epoch 83/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3381\n",
      "Epoch 84/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3416\n",
      "Epoch 85/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3362\n",
      "Epoch 86/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3325\n",
      "Epoch 87/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.3421\n",
      "Epoch 88/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3505\n",
      "Epoch 89/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3376\n",
      "Epoch 90/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3517\n",
      "Epoch 91/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3540\n",
      "Epoch 92/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3481\n",
      "Epoch 93/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3436\n",
      "Epoch 94/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3386\n",
      "Epoch 95/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3373\n",
      "Epoch 96/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3474\n",
      "Epoch 97/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3480\n",
      "Epoch 98/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3352\n",
      "Epoch 99/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3565\n",
      "Epoch 100/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19d49251050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model using ANN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape = (X.shape[1], )), \n",
    "    keras.layers.Dense(15, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', # log-loss function\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f394e025-3e28-4edd-b866-1eaef035187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3352999687194824, 0.8666666746139526]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa8bd47-30aa-44b8-b06a-ede764365dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "yp = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e74c902e-2013-472e-a847-2191485c314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probability into 0 or 1 based on cutoff of 0.5\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in yp:\n",
    "    if i < 0.5:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae82333-a98e-406a-b5fd-8f1c12cc5558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      2416\n",
      "           1       0.79      0.43      0.56       584\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.83      0.70      0.74      3000\n",
      "weighted avg       0.86      0.87      0.85      3000\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2350,   66],\n",
       "       [ 334,  250]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('---------------------------------------------------------------------------')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dec4276-16e9-4dba-80dd-9b5527f5d791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (4, 3))\n",
    "ax.matshow(cm, cmap = 'viridis')\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize = 12)\n",
    "ax.set_ylabel('Truth', fontsize = 12)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        color = 'black' if cm[i, j] > cm.max() / 2 else 'white'\n",
    "        text = ax.text(j, i, f'{cm[i, j]}', ha='center', va='center', color=color)\n",
    "\n",
    "        rect = Rectangle((j-0.5, i-0.5), 1, 1, fill = False, edgecolor = 'white', lw = 2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3339b43a-9318-4a5a-8a22-d6d4ff2625f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dictionary = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', \n",
    "                    'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Grays', 'Greens', 'Greens_r', 'Greys', \n",
    "                    'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', \n",
    "                    'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', \n",
    "                    'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', \n",
    "                    'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', \n",
    "                    'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', \n",
    "                    'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', \n",
    "                    'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', \n",
    "                    'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', \n",
    "                    'gist_gray_r', 'gist_grey', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', \n",
    "                    'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gist_yerg', 'gnuplot', \n",
    "                    'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'grey', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', \n",
    "                    'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', \n",
    "                    'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', \n",
    "                    'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', \n",
    "                    'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', \n",
    "                    'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1a8e8-748c-4fde-bc9f-a3d7b32bd6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
